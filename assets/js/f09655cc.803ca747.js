"use strict";(globalThis.webpackChunkphysical_ai_robotics_textbook=globalThis.webpackChunkphysical_ai_robotics_textbook||[]).push([[212],{94:(e,a,i)=>{i.d(a,{A:()=>n});const n=i.p+"assets/images/visualization_SLAm-1b1235fbae2ad4cc797a830dc61e1d8e.jpg"},2125:(e,a,i)=>{i.d(a,{A:()=>n});const n=i.p+"assets/images/SLAM-7cba57443dda04b234a88dc0416189c0.png"},4319:(e,a,i)=>{i.d(a,{A:()=>n});const n=i.p+"assets/images/SLAM_Flow_chart-d4a01e4e9ae4403eeb886911b5f7b3d8.png"},5128:(e,a,i)=>{i.d(a,{A:()=>n});const n="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNjAwIiBoZWlnaHQ9IjQwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8c3R5bGU+CiAgICAuY29tcG9uZW50IHsgZmlsbDogI2Y5ZjlmOTsgc3Ryb2tlOiAjMzMzOyBzdHJva2Utd2lkdGg6IDI7IH0KICAgIC50ZXh0IHsgZm9udC1mYW1pbHk6IHNhbnMtc2VyaWY7IGZvbnQtc2l6ZTogMTRweDsgdGV4dC1hbmNob3I6IG1pZGRsZTsgfQogICAgLnRpdGxlIHsgZm9udC1mYW1pbHk6IHNhbnMtc2VyaWY7IGZvbnQtc2l6ZTogMThweDsgdGV4dC1hbmNob3I6IG1pZGRsZTsgZm9udC13ZWlnaHQ6IGJvbGQ7IH0KICAgIC5hcnJvdyB7IHN0cm9rZTogIzMzMzsgc3Ryb2tlLXdpZHRoOiAyOyBtYXJrZXItZW5kOiB1cmwoI2Fycm93aGVhZCk7IH0KICAgIC5kYXNoZWQtYXJyb3cgeyBzdHJva2U6ICMzMzM7IHN0cm9rZS13aWR0aDogMjsgc3Ryb2tlLWRhc2hhcnJheTogNSw1OyBtYXJrZXItZW5kOiB1cmwoI2Fycm93aGVhZCk7IH0KICA8L3N0eWxlPgoKICA8ZGVmcz4KICAgIDxtYXJrZXIgaWQ9ImFycm93aGVhZCIgbWFya2VyV2lkdGg9IjEwIiBtYXJrZXJIZWlnaHQ9IjciIHJlZlg9IjAiIHJlZlk9IjMuNSIgb3JpZW50PSJhdXRvIj4KICAgICAgPHBvbHlnb24gcG9pbnRzPSIwIDAsIDEwIDMuNSwgMCA3IiAvPgogICAgPC9tYXJrZXI+CiAgPC9kZWZzPgoKICA8dGV4dCB4PSIzMDAiIHk9IjMwIiBjbGFzcz0idGl0bGUiPk1vZHVsZSAzOiBBSS1Sb2JvdCBCcmFpbiBBcmNoaXRlY3R1cmU8L3RleHQ+CgogIDwhLS0gSXNhYWMgU2ltIC0tPgogIDxyZWN0IHg9IjUwIiB5PSIxMDAiIHdpZHRoPSIxNTAiIGhlaWdodD0iNjAiIHJ4PSIxMCIgY2xhc3M9ImNvbXBvbmVudCIgLz4KICA8dGV4dCB4PSIxMjUiIHk9IjEzNSIgY2xhc3M9InRleHQiPk5WSURJQSBJc2FhYyBTaW08L3RleHQ+CiAgPHRleHQgeD0iMTI1IiB5PSIxNTAiIGNsYXNzPSJ0ZXh0Ij4oU2ltdWxhdGlvbik8L3RleHQ+CgogIDwhLS0gSXNhYWMgUk9TIC0tPgogIDxyZWN0IHg9IjIyNSIgeT0iMjAwIiB3aWR0aD0iMTUwIiBoZWlnaHQ9IjYwIiByeD0iMTAiIGNsYXNzPSJjb21wb25lbnQiIC8+CiAgPHRleHQgeD0iMzAwIiB5PSIyMzUiIGNsYXNzPSJ0ZXh0Ij5Jc2FhYyBST1M8L3RleHQ+CiAgPHRleHQgeD0iMzAwIiB5PSIyNTAiIGNsYXNzPSJ0ZXh0Ij4oR1BVLUFjY2VsZXJhdGVkIFJPUyk8L3RleHQ+CgogIDwhLS0gTmF2MiAtLT4KICA8cmVjdCB4PSI0NTAiIHk9IjEwMCIgd2lkdGg9IjEwMCIgaGVpZ2h0PSI2MCIgcng9IjEwIiBjbGFzcz0iY29tcG9uZW50IiAvPgogIDx0ZXh0IHg9IjUwMCIgeT0iMTM1IiBjbGFzcz0idGV4dCI+TmF2MjwvdGV4dD4KICA8dGV4dCB4PSI1MDAiIHk9IjE1MCIgY2xhc3M9InRleHQiPihOYXZpZ2F0aW9uIFN0YWNrKTwvdGV4dD4KCiAgPCEtLSBST1MgMiAoSW1wbGljaXQpIC0tPgogIDxyZWN0IHg9IjIyNSIgeT0iMzAwIiB3aWR0aD0iMTUwIiBoZWlnaHQ9IjQwIiByeD0iMTAiIGNsYXNzPSJjb21wb25lbnQiIC8+CiAgPHRleHQgeD0iMzAwIiB5PSIzMjUiIGNsYXNzPSJ0ZXh0Ij5ST1MgMiAoUm9ib3QpPC90ZXh0PgogIAogIDwhLS0gQXJyb3dzIC0tPgogIDxsaW5lIHgxPSIxMjUiIHkxPSIxNjAiIHgyPSIzMDAiIHkyPSIyMDAiIGNsYXNzPSJhcnJvdyIgLz4KICA8dGV4dCB4PSIxODAiIHk9IjE4MCIgY2xhc3M9InRleHQiPlNlbnNvciBEYXRhLDwvdGV4dD4KICA8dGV4dCB4PSIxODAiIHk9IjE5NSIgY2xhc3M9InRleHQiPkdyb3VuZCBUcnV0aCAoQnJpZGdlKTwvdGV4dD4KCiAgPGxpbmUgeDE9IjMwMCIgeTE9IjI2MCIgeDI9IjMwMCIgeTI9IjMwMCIgY2xhc3M9ImFycm93IiAvPgogIDx0ZXh0IHg9IjM1MCIgeT0iMjgwIiBjbGFzcz0idGV4dCI+Q29udHJvbCBDb21tYW5kczwvdGV4dD4KICAKICA8bGluZSB4MT0iMzc1IiB5MT0iMjMwIiB4Mj0iNDUwIiB5Mj0iMTMwIiBjbGFzcz0iYXJyb3ciIC8+CiAgPHRleHQgeD0iNDEwIiB5PSIxOTAiIGNsYXNzPSJ0ZXh0Ij5Hb2FscywgTWFwcyw8L3RleHQ+CiAgPHRleHQgeD0iNDEwIiB5PSIyMDUiIGNsYXNzPSJ0ZXh0Ij5PZG9tPC90ZXh0PgoKICA8bGluZSB4MT0iNTAwIiB5MT0iMTYwIiB4Mj0iMzc1IiB5Mj0iMjAwIiBjbGFzcz0iYXJyb3ciIC8+CiAgPHRleHQgeD0iNDEwIiB5PSIxNzAiIGNsYXNzPSJ0ZXh0Ij5WZWxvY2l0eSBDb21tYW5kczwvdGV4dD4KCjwvc3ZnPgo="},5680:(e,a,i)=>{i.d(a,{xA:()=>g,yg:()=>I});var n=i(6540);function t(e,a,i){return a in e?Object.defineProperty(e,a,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[a]=i,e}function r(e,a){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter(function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable})),i.push.apply(i,n)}return i}function o(e){for(var a=1;a<arguments.length;a++){var i=null!=arguments[a]?arguments[a]:{};a%2?r(Object(i),!0).forEach(function(a){t(e,a,i[a])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):r(Object(i)).forEach(function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(i,a))})}return e}function s(e,a){if(null==e)return{};var i,n,t=function(e,a){if(null==e)return{};var i,n,t={},r=Object.keys(e);for(n=0;n<r.length;n++)i=r[n],a.indexOf(i)>=0||(t[i]=e[i]);return t}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)i=r[n],a.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(t[i]=e[i])}return t}var l=n.createContext({}),c=function(e){var a=n.useContext(l),i=a;return e&&(i="function"==typeof e?e(a):o(o({},a),e)),i},g=function(e){var a=c(e.components);return n.createElement(l.Provider,{value:a},e.children)},m="mdxType",p={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},d=n.forwardRef(function(e,a){var i=e.components,t=e.mdxType,r=e.originalType,l=e.parentName,g=s(e,["components","mdxType","originalType","parentName"]),m=c(i),d=t,I=m["".concat(l,".").concat(d)]||m[d]||p[d]||r;return i?n.createElement(I,o(o({ref:a},g),{},{components:i})):n.createElement(I,o({ref:a},g))});function I(e,a){var i=arguments,t=a&&a.mdxType;if("string"==typeof e||t){var r=i.length,o=new Array(r);o[0]=d;var s={};for(var l in a)hasOwnProperty.call(a,l)&&(s[l]=a[l]);s.originalType=e,s[m]="string"==typeof e?e:t,o[1]=s;for(var c=2;c<r;c++)o[c]=i[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,i)}d.displayName="MDXCreateElement"},6378:(e,a,i)=>{i.r(a),i.d(a,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var n=i(8168),t=(i(6540),i(5680));const r={id:"09-isaac-ros-vslam",title:"Chapter 9: Isaac ROS and VSLAM",sidebar_label:"9. Isaac ROS and VSLAM"},o=void 0,s={unversionedId:"09-isaac-ros-vslam",id:"09-isaac-ros-vslam",title:"Chapter 9: Isaac ROS and VSLAM",description:"Chapter 9: Isaac ROS and VSLAM",source:"@site/docs/09-isaac-ros-vslam.md",sourceDirName:".",slug:"/09-isaac-ros-vslam",permalink:"/AI-driven-development/docs/09-isaac-ros-vslam",draft:!1,editUrl:"https://github.com/ai-driven-development/AI_Robotics_book/tree/main/docs/09-isaac-ros-vslam.md",tags:[],version:"current",sidebarPosition:9,frontMatter:{id:"09-isaac-ros-vslam",title:"Chapter 9: Isaac ROS and VSLAM",sidebar_label:"9. Isaac ROS and VSLAM"},sidebar:"tutorialSidebar",previous:{title:"8. NVIDIA Isaac Sim Introduction",permalink:"/AI-driven-development/docs/08-isaac-sim-intro"},next:{title:"10. Nav2 Path Planning",permalink:"/AI-driven-development/docs/10-nav2-path-planning"}},l={},c=[{value:"Chapter 9: Isaac ROS and VSLAM",id:"chapter-9-isaac-ros-and-vslam",level:2},{value:"9.1 What is Isaac ROS?",id:"91-what-is-isaac-ros",level:3},{value:"9.2 Visual SLAM (vSLAM)",id:"92-visual-slam-vslam",level:3},{value:"How <code>visual_slam</code> works (Simplified)",id:"how-visual_slam-works-simplified",level:4},{value:"Integrating <code>visual_slam</code> in ROS 2",id:"integrating-visual_slam-in-ros-2",level:4},{value:"9.3 Hardware Acceleration",id:"93-hardware-acceleration",level:3},{value:"9.4 Perception Pipelines",id:"94-perception-pipelines",level:3}],g={toc:c},m="wrapper";function p({components:e,...a}){return(0,t.yg)(m,(0,n.A)({},g,a,{components:e,mdxType:"MDXLayout"}),(0,t.yg)("h2",{id:"chapter-9-isaac-ros-and-vslam"},"Chapter 9: Isaac ROS and VSLAM"),(0,t.yg)("p",null,(0,t.yg)("strong",{parentName:"p"},"Objective"),": Implement hardware-accelerated perception pipelines using Isaac ROS."),(0,t.yg)("h3",{id:"91-what-is-isaac-ros"},"9.1 What is Isaac ROS?"),(0,t.yg)("p",null,(0,t.yg)("strong",{parentName:"p"},"Isaac ROS")," is a collection of hardware-accelerated ROS 2 packages that enable developers to build high-performance robotics applications on NVIDIA hardware (e.g., Jetson platforms, RTX GPUs). It leverages NVIDIA's GPU capabilities for computationally intensive tasks like computer vision, simultaneous localization and mapping (SLAM), and AI inference."),(0,t.yg)("p",null,"Key features of Isaac ROS:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"GPU Acceleration"),": Optimized CUDA kernels for common robotics algorithms."),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Containerization"),": Delivered as Docker containers, ensuring easy deployment and reproducibility."),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Modular Design"),": Provides building blocks for various perception and navigation pipelines."),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Integration with Isaac Sim"),": Seamless transfer of learned policies from simulation to real robots.")),(0,t.yg)("p",null,(0,t.yg)("img",{alt:"AI Robot Brain Architecture",src:i(5128).A,width:"600",height:"400"})),(0,t.yg)("p",null,(0,t.yg)("img",{alt:"SLAM Visualization",src:i(94).A,width:"2698",height:"1149"}),"\n",(0,t.yg)("img",{alt:"SLAM Flow Chart",src:i(4319).A,width:"637",height:"324"}),"\n",(0,t.yg)("img",{alt:"SLAM Simple",src:i(2125).A,width:"810",height:"314"})),(0,t.yg)("h3",{id:"92-visual-slam-vslam"},"9.2 Visual SLAM (vSLAM)"),(0,t.yg)("p",null,(0,t.yg)("strong",{parentName:"p"},"SLAM (Simultaneous Localization and Mapping)")," is a fundamental problem in robotics: how does a robot build a map of an unknown environment while simultaneously keeping track of its own location within that map? ",(0,t.yg)("strong",{parentName:"p"},"Visual SLAM (vSLAM)")," uses camera feeds as its primary sensor input."),(0,t.yg)("p",null,"Isaac ROS provides highly optimized vSLAM packages. One prominent example is the ",(0,t.yg)("inlineCode",{parentName:"p"},"visual_slam")," ROS 2 node, which implements a robust visual-inertial odometry (VIO) pipeline."),(0,t.yg)("h4",{id:"how-visual_slam-works-simplified"},"How ",(0,t.yg)("inlineCode",{parentName:"h4"},"visual_slam")," works (Simplified)"),(0,t.yg)("ol",null,(0,t.yg)("li",{parentName:"ol"},(0,t.yg)("strong",{parentName:"li"},"Sensor Input"),": Takes synchronized image streams (mono/stereo) and IMU data."),(0,t.yg)("li",{parentName:"ol"},(0,t.yg)("strong",{parentName:"li"},"Feature Extraction"),": Detects and tracks salient features across image frames."),(0,t.yg)("li",{parentName:"ol"},(0,t.yg)("strong",{parentName:"li"},"Pose Estimation"),": Estimates the camera's (and thus the robot's) 6-DOF pose relative to the environment."),(0,t.yg)("li",{parentName:"ol"},(0,t.yg)("strong",{parentName:"li"},"Mapping"),": Builds a sparse or dense map of the environment using the estimated poses."),(0,t.yg)("li",{parentName:"ol"},(0,t.yg)("strong",{parentName:"li"},"Loop Closure"),": Recognizes previously visited locations to correct accumulated errors and optimize the map and trajectory.")),(0,t.yg)("h4",{id:"integrating-visual_slam-in-ros-2"},"Integrating ",(0,t.yg)("inlineCode",{parentName:"h4"},"visual_slam")," in ROS 2"),(0,t.yg)("p",null,"You typically run Isaac ROS packages inside Docker containers. An example ROS 2 launch file for ",(0,t.yg)("inlineCode",{parentName:"p"},"visual_slam")," might look like this:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-python"},"import os\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import LaunchConfiguration\nfrom ament_index_python.packages import get_package_share_directory\n\ndef generate_launch_description():\n    # Path to the visual_slam package\n    visual_slam_pkg_dir = get_package_share_directory('isaac_ros_visual_slam')\n\n    # Declare arguments\n    declare_namespace_cmd = DeclareLaunchArgument(\n        'namespace',\n        default_value='',\n        description='Namespace for the visual_slam node')\n\n    # visual_slam node\n    visual_slam_node = Node(\n        package='isaac_ros_visual_slam',\n        executable='visual_slam_node',\n        name='visual_slam_node',\n        output='screen',\n        namespace=LaunchConfiguration('namespace'),\n        parameters=[\n            os.path.join(visual_slam_pkg_dir, 'params', 'visual_slam_node_params.yaml'),\n            {'enable_imu_fusion': True,\n             'enable_dev_interfaces': False,\n             'denoise_imu_data': True,\n             'map_frame': 'map',\n             'odom_frame': 'odom',\n             'base_frame': 'base_link',\n             'camera_frame': 'camera_link',\n             'gyro_bias_sigma': 0.0001,\n             'accel_bias_sigma': 0.001}\n        ],\n        remappings=[\n            ('image', '/camera/image_raw'),\n            ('camera_info', '/camera/camera_info'),\n            ('imu', '/imu/data')\n        ]\n    )\n\n    return LaunchDescription([\n        declare_namespace_cmd,\n        visual_slam_node\n    ])\n")),(0,t.yg)("h3",{id:"93-hardware-acceleration"},"9.3 Hardware Acceleration"),(0,t.yg)("p",null,"The true power of Isaac ROS comes from its ability to leverage NVIDIA GPUs. Many algorithms are implemented using CUDA and TensorRT, enabling real-time performance even with high-resolution sensor data. This is critical for mobile robots, where latency and processing power are often limited."),(0,t.yg)("p",null,"Developers building with Isaac ROS benefit from:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Lower Latency"),": Faster processing of sensor data."),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Higher Throughput"),": Ability to handle more data (e.g., higher resolution cameras, more sensors)."),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Reduced CPU Load"),": Offloading computation from the CPU to the GPU, freeing up CPU cycles for other tasks.")),(0,t.yg)("h3",{id:"94-perception-pipelines"},"9.4 Perception Pipelines"),(0,t.yg)("p",null,"Isaac ROS provides building blocks for various perception tasks beyond SLAM. You can combine different nodes (e.g., ",(0,t.yg)("inlineCode",{parentName:"p"},"isaac_ros_apriltag"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"isaac_ros_segmentation"),") to create custom perception pipelines. For example:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Object Detection"),": Using pre-trained models or custom-trained models (often with synthetic data from Isaac Sim) to identify objects in the environment."),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Segmentation"),": Identifying and classifying different regions within an image."),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"3D Reconstruction"),": Building 3D models of the environment from sensor data.")),(0,t.yg)("p",null,'These hardware-accelerated pipelines are essential for giving robots the "eyes" and "brains" they need to understand and interact with the physical world intelligently.'))}p.isMDXComponent=!0}}]);